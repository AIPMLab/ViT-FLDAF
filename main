import numpy as np
import torch
import time
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import ImageFolder
import torch.optim as optim
import timm
import copy
import logging
from sklearn.metrics import confusion_matrix
from torch.optim.lr_scheduler import ReduceLROnPlateau

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s %(levelname)s %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S',
                    handlers=[
                        logging.FileHandler("./FedVit_efficient_logs/dataset4_log", mode='w'),
                        logging.StreamHandler()
                    ])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 定义数据增强和转换
_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    # transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    # transforms.RandomResizedCrop(224),
    # transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

Num_clients = 4
# pathes = './data/RealSkin/client_'
# pathes = './dataset/client_'
pathes = './RCNA_ICH/client_'
client_weights = [float(1 / (Num_clients - 1)) for idx in range(0, Num_clients - 1)]
# client_weights.append(0.2)
# client_weights.append(0.5)
# client_weights.append(0.3)

dataset = [ImageFolder(root=pathes + str(idx), transform=transform) for idx in range(0, Num_clients)]
train_dataset = [dataset[idx] for idx in range(0, Num_clients - 1)]
test_dataset = dataset[Num_clients - 1]

train_loader = [DataLoader(train_dataset[idx], batch_size=32, shuffle=True, drop_last=True) for idx in
                range(0, Num_clients - 1)]

test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=True)


# dataset.append(ImageFolder(root='./data/OfficeHome/Art', transform=transform))
# dataset.append(ImageFolder(root='./data/OfficeHome/Product', transform=transform))
# dataset.append(ImageFolder(root='./data/OfficeHome/RealWorld', transform=transform))e
# dataset.append(ImageFolder(root='./data/BrainTumor/client_0', transform=transform))
# dataset.append(ImageFolder(root='./data/BrainTumor/client_1', transform=transform))
# dataset.append(ImageFolder(root='./data/BrainTumor/client_2', transform=transform))
# dataset.append(ImageFolder(root='./data/BrainTumor/client_3', transform=_transform))
# dataset.append(ImageFolder(root='./data/OfficeHome/Clipart', transform=transform))

# dataset.append(ImageFolder(root='./dermnet/client_0', transform=transform))
# dataset.append(ImageFolder(root='./dermnet/client_1', transform=transform))
# dataset.append(ImageFolder(root='./dermnet/client_2', transform=transform))
# dataset.append(ImageFolder(root='./dermnet/client_3', transform=_transform))

# dataset.append(ImageFolder(root='./test/client_0', transform=transform))
# dataset.append(ImageFolder(root='./test/client_1', transform=transform))
# dataset.append(ImageFolder(root='./test/client_2', transform=transform))
# dataset.append(ImageFolder(root='./test/client_3', transform=_transform))
# dataset.append(ImageFolder(root='./RCNA_ICH/client_0', transform=transform))
# dataset.append(ImageFolder(root='./RCNA_ICH/client_1', transform=transform))
# dataset.append(ImageFolder(root='./RCNA_ICH/client_2', transform=transform))
# dataset.append(ImageFolder(root='./RCNA_ICH/client_3', transform=_transform))
# dataset.append(ImageFolder(root='./data/oral_cancer/client_0', transform=transform))
# dataset.append(ImageFolder(root='./data/oral_cancer/client_1', transform=transform))
# dataset.append(ImageFolder(root='./data/oral_cancer/client_2', transform=transform))
# dataset.append(ImageFolder(root='./data/oral_cancer/client_3', transform=_transform))
#
# dataset.append(ImageFolder(root='./data/face_recognition/client_0', transform=transform))
# dataset.append(ImageFolder(root='./data/face_recognition/client_1', transform=transform))
# dataset.append(ImageFolder(root='./data/face_recognition/client_2', transform=transform))
# dataset.append(ImageFolder(root='./data/face_recognition/client_3', transform=_transform))
# dataset.append(ImageFolder(root='./dataset/client_0', transform=transform))
# dataset.append(ImageFolder(root='./dataset/client_1', transform=transform))
# dataset.append(ImageFolder(root='./dataset/client_2', transform=transform))
# dataset.append(ImageFolder(root='./dataset/client_3', transform=_transform))
# dataset.append(ImageFolder(root='./data/RealSkin/client_0', transform=transform))
# dataset.append(ImageFolder(root='./data/RealSkin/client_1', transform=transform))
# dataset.append(ImageFolder(root='./data/RealSkin/client_2', transform=transform))
# dataset.append(ImageFolder(root='./data/RealSkin/client_3', transform=_transform))

# dataset.append(ImageFolder(root='./differe05,025,015,01)/client_2', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/RSNA-ICH(05,02nt_distribution_dataset/RSNA-ICH(05,025,015,01)/client_0', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/RSNA-ICH(05,025,015,01)/client_1', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/RSNA-ICH(5,015,01)//client_3', transform=_transform))

# dataset.append(ImageFolder(root='./different_distribution_dataset/RSNA-ICH(03,03,02,01)/client_0', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/RSNA-ICH(03,03,02,01)/client_1', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/RSNA-ICH(03,03,02,01)/client_2', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/RSNA-ICH(03,03,02,01)/client_3', transform=_transform))

# dataset.append(ImageFolder(root='./different_distribution_dataset/ISIC(03,03,02,01)/client_0', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/ISIC(03,03,02,01)/client_1', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/ISIC(03,03,02,01)/client_2', transform=transform))
# dataset.append(ImageFolder(root='./different_distribution_dataset/ISIC(03,03,02,01)/client_3', transform=_transform))
# dataset.append(ImageFolder(root='./brain tumor dataset/client_0', transform=transform))
# dataset.append(ImageFolder(root='./brain tumor dataset/client_1', transform=transform))
# dataset.append(ImageFolder(root='./brain tumor dataset/client_2', transform=transform))
# dataset.append(ImageFolder(root='./brain tumor dataset/client_3', transform=_transform))

# dataset.append(ImageFolder(root='./data/BrainTumor/client_0', transform=transform))
# dataset.append(ImageFolder(root='./data/BrainTumor/client_1', transform=transform))
# dataset.append(ImageFolder(root='./data/BrainTumor/client_2', transform=transform))
# dataset.append(ImageFolder(root='./data/BrainTumor/client_3', transform=_transform))
#
# dataset.append(ImageFolder(root='./comparison_datasets/Food2kTrain/client_0', transform=transform))
# dataset.append(ImageFolder(root='./comparison_datasets/Food2kTrain/client_1', transform=transform))
# dataset.append(ImageFolder(root='./comparison_datasets/Food2kTrain/client_2', transform=transform))
# dataset.append(ImageFolder(root='./comparison_datasets/Food2kTrain/client_3', transform=_transform))


class CustomViT(nn.Module):
    def __init__(self, num_classes):
        super(CustomViT, self).__init__()
        self.original_model = timm.create_model('vit_small_patch16_224', pretrained=True)
        self.original_model.head = nn.Linear(self.original_model.head.in_features, num_classes)

        # set gamma to be learnable and set the initial value as 2.0
        self.gamma = nn.Parameter(torch.tensor(2.0, device=device), requires_grad=True)

    def forward(self, x):
        x = self.original_model.forward_features(x)
        x = self.original_model.norm(x)
        y = self.original_model.head(x)
        return y


num_classes = 5
glo_model = CustomViT(num_classes).to(device)

models = [copy.deepcopy(glo_model) for _ in range(3)]
for model in models:
    model.to(device)


def compute_imbalance_parameters(client_data, client_weights, num_classes):
    # 1. Calculate Class-level Imbalance (c_{f,i}) - Eq 8
    # Use only training clients for stats
    num_train_clients = len(client_weights)

    total_samples_train = 0
    train_class_counts = {cls: 0 for cls in range(num_classes)}

    for k in range(num_train_clients):
        counts = client_data[k]
        total_samples_train += sum(counts.values())
        for cls, count in counts.items():
            train_class_counts[cls] += count

    c_f_class = {}
    for cls in range(num_classes):
        n_i = train_class_counts[cls]
        if n_i > 0:
            c_f_class[cls] = (total_samples_train - n_i) / n_i
        else:
            c_f_class[cls] = 0.0

    # 2. Calculate Client-level Imbalance (c_{f, client}) - Eq 14 & 7
    c_f_client = 0.0
    for k in range(num_train_clients):
        counts = client_data[k]
        N_k = sum(counts.values())

        # Calculate c_k (Eq 7)
        c_k_sum = 0.0
        for cls in range(num_classes):
            n_ki = counts.get(cls, 0)
            # Avoid division by zero with small constant (e.g., 1)
            n_ki_safe = max(n_ki, 1)
            c_ki = (N_k - n_ki_safe) / n_ki_safe
            c_k_sum += c_ki

        c_k = c_k_sum / num_classes
        c_f_client += client_weights[k] * c_k

    return c_f_class, c_f_client


def quality_aware_focal_loss(y_true, y_pred, gamma, cf):
    # This function seems unused in the main training loop, but keeping it consistent if needed
    pt = torch.where(y_true == 1, y_pred, 1 - y_pred)
    focal_weight = (1 - pt) ** gamma
    loss = - (1 + cf) * torch.log(pt + 1e-8) * focal_weight
    return loss.mean()


def custom_loss(outputs, labels, model, c_f_class, c_f_client, lambda_val=0.5, weight_decay=1e-5):
    # DAFL: - (1 + c_{f,t}) * (1 - p_t)^gamma * log(p_t)
    # c_{f,t} = lambda * c_{f,client} + (1-lambda) * c_{f,i}

    probs = torch.nn.functional.softmax(outputs, dim=1)
    gamma = model.gamma

    # Get probabilities of the true classes (p_t)
    pt = probs.gather(1, labels.view(-1, 1)).view(-1)

    # Get class-level imbalance coefficients for the true classes
    c_fi_batch = torch.tensor([c_f_class[l.item()] for l in labels], device=device)

    # Combine with client-level imbalance using lambda
    cfs = lambda_val * c_f_client + (1 - lambda_val) * c_fi_batch

    # Calculate Dynamic Adaptive Focal Loss
    focal_weight = (1 - pt) ** gamma
    focal_loss = - (1 + cfs) * focal_weight * torch.log(pt + 1e-8)

    total_loss = focal_loss.mean()

    # L1 Regularization for model parameters (optional, kept from original structure if needed)
    l1_regularization = torch.tensor(0., device=device)
    for param in model.parameters():
        if param.requires_grad:
            l1_regularization += torch.norm(param, 1)

    total_loss += (weight_decay * l1_regularization) * 0.1

    return total_loss


def train(model, train_loader, optimizer, scheduler, c_f_class, c_f_client, lambda_val, epochs=50):
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = custom_loss(outputs, labels, model, c_f_class, c_f_client, lambda_val)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        # 在每个epoch结束时更新学习率
        scheduler.step()

        avg_loss = total_loss / len(train_loader)
        logging.info(f"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss:.4f}")
    return model


# 确保在初始化学习率调度器之前初始化优化器
optimizers = [optim.Adam(params=[{'params': models[idx].parameters()}], lr=1e-3, betas=(0.9, 0.98), eps=1e-6) for idx in
              range(3)]
schedulers = [copy.deepcopy(torch.optim.lr_scheduler.StepLR(optimizers[idx], step_size=30, gamma=0.1)) for idx in
              range(3)]


def evaluate(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    all_predicted = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            all_predicted.extend(predicted.view(-1).cpu().numpy())
            all_labels.extend(labels.view(-1).cpu().numpy())

    accuracy = correct / total * 100
    logging.info(f'Accuracy on test set: {accuracy:.2f}%')

    cm = confusion_matrix(all_labels, all_predicted)
    logging.info(f'Confusion Matrix:\n{cm}')
    # print(model.mask_parameters)
    return accuracy, cm


available_models = timm.list_models(pretrained=True)


# print(available_models)


def LocalTraining(models, train_loader, c_f_class, c_f_client, lambda_val):
    model_new = []
    for i, model in enumerate(models):
        logging.info('Client: %s Local Training', i)
        model_new.append(
            train(model, train_loader[i], optimizers[i], schedulers[i], c_f_class, c_f_client, lambda_val, epochs=1))
    return model_new


def communication(server_model, models, client_weights):
    client_num = len(models)
    with torch.no_grad():
        for key in server_model.state_dict().keys():
            temp = torch.zeros_like(server_model.state_dict()[key], dtype=torch.float64)
            for client_idx in range(client_num):
                temp += client_weights[client_idx] * models[client_idx].state_dict()[key]

            server_model.state_dict()[key].data.copy_(temp)
            for client_idx in range(client_num):
                models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])

    return server_model, models


def FederatedTraining(models, glo_model, train_loader, c_f_class, c_f_client, lambda_val):
    start_time = time.time()

    results = []
    best_accuracy = 0
    for i in range(0, 50):
        models = LocalTraining(models, train_loader, c_f_class, c_f_client, lambda_val)
        logging.info('Started Communication!')
        glo_model, models = communication(glo_model, models, client_weights)
        logging.info('Started Evaluation')
        acc, cm = evaluate(glo_model, test_loader)
        results.append([acc])
        print(acc)
        if acc > best_accuracy:
            best_accuracy = acc
            model_save_path = 'models/DFL_lr_1e-3_RSNA.pth'
            torch.save(glo_model.state_dict(), model_save_path)
            logging.info(f"New best model with accuracy: {best_accuracy:.2f}% saved to {model_save_path}")

    end_time = time.time()
    total_time = end_time - start_time
    logging.info(f"Total training time: {total_time // 3600}h {(total_time % 3600) // 60}m {total_time % 60:.2f}s")

    save_results = np.array(results, dtype=float)
    np.savetxt('logs/DFL_lr_1e-3 _RSNA', save_results, delimiter=',', fmt='%.6f')

    return results, cm


#
def get_client_data_stats(dataset):
    """动态生成每个客户端的数据样本数"""
    client_data = []
    for client_dataset in dataset:
        class_counts = {}
        # Use .targets if available for faster counting
        if hasattr(client_dataset, 'targets'):
            targets = client_dataset.targets
            # If targets is a list, we can iterate. If it's a tensor, we can use bincount (if numeric)
            # Assuming standard ImageFolder list of ints
            for label in targets:
                # Handle potential tensor wrapper
                if isinstance(label, torch.Tensor):
                    label = label.item()
                if label not in class_counts:
                    class_counts[label] = 0
                class_counts[label] += 1
        else:
            for _, label in client_dataset:
                if label not in class_counts:
                    class_counts[label] = 0
                class_counts[label] += 1
        client_data.append(class_counts)
    return client_data


# 动态生成client_data
client_data = get_client_data_stats(dataset)

# Calculate client weights based on data size (Weighted Aggregation Strategy)
# Only for the training clients (0 to Num_clients-2)
train_client_data = client_data[:Num_clients - 1]
total_train_samples = sum(sum(c.values()) for c in train_client_data)
client_weights = [sum(c.values()) / total_train_samples for c in train_client_data]
logging.info(f"Calculated client weights: {client_weights}")

c_f_class, c_f_client = compute_imbalance_parameters(client_data, client_weights, num_classes)

# Set lambda parameter (balancing coefficient)
lambda_val = 0.5

results, cm = FederatedTraining(models, glo_model, train_loader, c_f_class, c_f_client, lambda_val)
model_save_path = 'saved_models'

torch.save(glo_model.state_dict(), model_save_path)
